{"id":494,"date":"2023-09-30T19:01:04","date_gmt":"2023-09-30T23:01:04","guid":{"rendered":"http:\/\/localhost\/homepage\/?page_id=494"},"modified":"2024-02-04T13:52:26","modified_gmt":"2024-02-04T18:52:26","slug":"combining-spatial-and-temporal-abstraction-in-planning","status":"publish","type":"page","link":"http:\/\/localhost\/homepage\/combining-spatial-and-temporal-abstraction-in-planning\/","title":{"rendered":"Consciousness-Inspired Spatio-Temporal Abstractions for Better Generalization"},"content":{"rendered":"\n<p class=\"has-text-align-center\" style=\"font-size:17px\"><strong><em>Mingde Harry Zhao, Safa Alver, Harm van Seijen, Romain Laroche, Doina Precup, Yoshua Bengio<\/em><\/strong><\/p>\n\n\n\n<p class=\"has-text-align-center\"><a href=\"https:\/\/arxiv.org\/abs\/2310.00229\" data-type=\"link\" data-id=\"https:\/\/arxiv.org\/abs\/2310.00229\">paper<\/a> (arXiv) \/ <a href=\"https:\/\/github.com\/mila-iqia\/Skipper\" data-type=\"link\" data-id=\"https:\/\/github.com\/PwnerHarry\/Skipper\">GitHub<\/a><\/p>\n\n\n\n<p class=\"has-text-align-center has-small-font-size\">(work largely done during Harry, Harm and Romain&#8217;s time at MSR)<\/p>\n\n\n\n<p class=\"has-text-align-center has-base-background-color has-background has-medium-font-size\">[Accepted @<a href=\"https:\/\/iclr.cc\/\" data-type=\"link\" data-id=\"https:\/\/iclr.cc\/\">ICLR2024<\/a>]<em>This is our 2nd work on integrating conscious information processing behavior into Reinforcement Learning (RL) agents. Specifically, this paper seeks to address the inabilities of RL agents to generalize its learned skills in longer-term reasoning scenarios: a trained RL agent often cannot perform well in the target task due to the incompetence to handle training-evaluation discrepancy. This work builds upon <a href=\"http:\/\/localhost\/homepage\/the-new-umoma-opens-its-doors-2\/a-step-towards-conscious-planning\/\" data-type=\"page\" data-id=\"205\">our previous work on spatial abstraction (NeurIPS 2021)<\/a> in planning, raising the attention of the missing flavor of spatial abstraction in the existing temporal abstraction frameworks.<\/em><\/p>\n\n\n\n<figure class=\"wp-block-image size-large is-style-default\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"256\" src=\"http:\/\/localhost\/homepage\/wp-content\/uploads\/2023\/10\/fig_overall-1024x256.png\" alt=\"The overall framework of Skipper\n\" class=\"wp-image-517\" srcset=\"http:\/\/localhost\/homepage\/wp-content\/uploads\/2023\/10\/fig_overall-1024x256.png 1024w, http:\/\/localhost\/homepage\/wp-content\/uploads\/2023\/10\/fig_overall-300x75.png 300w, http:\/\/localhost\/homepage\/wp-content\/uploads\/2023\/10\/fig_overall-768x192.png 768w, http:\/\/localhost\/homepage\/wp-content\/uploads\/2023\/10\/fig_overall-1536x384.png 1536w, http:\/\/localhost\/homepage\/wp-content\/uploads\/2023\/10\/fig_overall.png 1790w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" \/><\/figure>\n\n\n\n<p class=\"has-medium-font-size\">We propose <strong><em>Skipper<\/em><\/strong>, a model-based RL agent that utilizes <strong>spatial<\/strong> and <strong>temporal<\/strong> abstractions to generalize learned skills in novel situations. It automatically decomposes the task at hand into smaller-scale, more manageable subtasks and hence enables sparse decision-making and focuses its computation on the relevant parts of the environment. This relies on the definition of a high-level <span style=\"text-decoration: underline;\">proxy problem<\/span> represented as a directed graph, in which vertices and edges are learned end-to-end using hindsight. Our theoretical analyses provide performance guarantees under appropriate assumptions and establish where our approach is expected to be helpful. Generalization-focused experiments validate Skipper\u2019s significant advantage in zero-shot generalization, compared to existing state-of-the-art hierarchical planning methods.<\/p>\n\n\n\n<p class=\"has-medium-font-size\">The highlights of this work include:<\/p>\n\n\n\n<p class=\"has-medium-font-size\"><strong>Theory-Motivated Divide-and-Conquer<\/strong>: we propose proxy problems with which a divide and conquer strategy could implement over longer-term reasoning for better generalization. Theoretical analyses are presented to show the applicable scenario and performance guarantees;<\/p>\n\n\n\n<p class=\"has-medium-font-size\"><strong>Spatio-temporal abstraction<\/strong>: temporal abstraction allows us to break down the given task into smaller ones, while spatial abstraction over the state features through an attention mechanism is used to improve local learning and generalization;<\/p>\n\n\n\n<p class=\"has-medium-font-size\"><strong>Decision-time planning<\/strong> is employed due to its ability to improve the policy in novel situations;<\/p>\n\n\n\n<p class=\"has-medium-font-size\"><strong>Learning end-to-end from hindsight, off-policy<\/strong>: to maximize sample efficiency and the ease of training, we propose to use auxiliary (off-)policy methods for edge estimation, and learn a context-conditioned checkpoint generation, both from hindsight experience replay;<\/p>\n\n\n\n<p class=\"has-medium-font-size\"><strong>Higher quality proxies<\/strong>: we introduce pruning techniques to improve the sparsity of the proxy problems, which leads to better quality;<\/p>\n\n\n\n<p class=\"has-medium-font-size\"><strong>Delusion suppression<\/strong>: we propose a delusion suppression technique to minimize the behavior of chasing non-existent outcomes. This is done by exposing the edge estimators to targets that would otherwise not exist in experience.<br><\/p>\n\n\n\n<figure class=\"wp-block-table is-style-stripes has-small-font-size\"><table><thead><tr><th><\/th><th><em>Skipper<\/em><\/th><th>Director<\/th><th>LEAP<\/th><th>adapted LEAP variant <\/th><\/tr><\/thead><tbody><tr><td><strong>Decision-Time Planning<\/strong><\/td><td>Dynamic Programming (fast)<\/td><td>No (only sample a conditioning latent)<\/td><td>Evolutionary Algorithms (slow)<\/td><td>Evolutionary Algorithms (slow)<\/td><\/tr><tr><td><strong>Offline Planning<\/strong><\/td><td>No<\/td><td>Yes<\/td><td>No<\/td><td>No<\/td><\/tr><tr><td><strong>Compatible with Terminal States<\/strong><\/td><td>Yes<\/td><td>Theoretically yes, suffer in experiments<\/td><td>No (TDM)<\/td><td>Yes<\/td><\/tr><tr><td><strong>Pretraining<\/strong><\/td><td>No<\/td><td>No<\/td><td>Yes<\/td><td>Yes<\/td><\/tr><tr><td><strong>Scope<\/strong><\/td><td>Theorem Condition, tested in navigation<\/td><td>General RL<\/td><td>Navigation<\/td><td>Navigation<\/td><\/tr><tr><td><strong>Sample Scheme<\/strong><\/td><td>Simple HER<\/td><td>Mixed Strategies<\/td><td>Mixed Strategies<\/td><td>Simple HER<\/td><\/tr><tr><td><strong>Generalizable Model<\/strong><\/td><td>Yes<\/td><td>No<\/td><td>No<\/td><td>Yes<\/td><\/tr><tr><td><strong>Generator Representation<\/strong><\/td><td>Discrete (partial description)<\/td><td>Discrete<\/td><td>Continuous<\/td><td>Discrete (partial description)<\/td><\/tr><tr><td><strong>Delusion Suppression<\/strong><\/td><td>Compatible, improves behavior<\/td><td>No<\/td><td>Compatible<\/td><td>Compatible, improves behavior dramatically<\/td><\/tr><tr><td><strong>Reconstruction<\/strong><\/td><td>Generator Only (not conditioned on actions), from state to future states<\/td><td>Representation and Model (atomic time-steps), from state to next state<\/td><td>Generator Only (not conditioned on actions), from state to state itself<\/td><td>Generator Only (not conditioned on actions), from state to future states<\/td><\/tr><tr><td><strong>OOD Adaptability<\/strong><\/td><td>good if the generator adapts well<\/td><td>poor because of overfitting value estimators on training tasks<\/td><td>good if the generator adapts well<\/td><td>good if the generator adapts well<\/td><\/tr><tr><td><br><br><br><br><strong>Limitations<\/strong><br><br><br><br><\/td><td>Not tested in partially-observable settings, not tested in generic RL settings; Checkpoints not task-aware<\/td><td>Cannot generalize well<\/td><td>very prone to delusional paths, not compatible with terminal states, sensitive to time budget for each sub-goal; Subgoals not task-aware<\/td><td>very prone to delusional paths; Subgoals not task-aware<\/td><\/tr><\/tbody><\/table><figcaption class=\"wp-element-caption\"><em>Comparison of the characteristics of the Hierarchical Planning (HP) agents in this work <\/em><\/figcaption><\/figure>\n\n\n\n<p><\/p>\n\n\n\n<p class=\"has-medium-font-size\">[Not in paper bonus] In the following figure, we showcase a size-64 batch of checkpoints generated by a trained <strong><em>Skipper<\/em><\/strong> agent, from the current state shown in the left. The non-existent checkpoints (that don&#8217;t belong to the state space) are color-inverted.<\/p>\n\n\n\n<figure class=\"wp-block-image size-large\"><img loading=\"lazy\" decoding=\"async\" width=\"1024\" height=\"512\" src=\"http:\/\/localhost\/homepage\/wp-content\/uploads\/2023\/10\/fig_example_checkpoints-1024x512.png\" alt=\"\" class=\"wp-image-512\" srcset=\"http:\/\/localhost\/homepage\/wp-content\/uploads\/2023\/10\/fig_example_checkpoints-1024x512.png 1024w, http:\/\/localhost\/homepage\/wp-content\/uploads\/2023\/10\/fig_example_checkpoints-300x150.png 300w, http:\/\/localhost\/homepage\/wp-content\/uploads\/2023\/10\/fig_example_checkpoints-768x384.png 768w, http:\/\/localhost\/homepage\/wp-content\/uploads\/2023\/10\/fig_example_checkpoints.png 1231w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" \/><\/figure>\n\n\n\n<p><strong><em>More contents coming soon!<\/em><\/strong><\/p>\n","protected":false},"excerpt":{"rendered":"<p>Mingde Harry Zhao, Safa Alver, Harm van Seijen, Romain Laroche, Doina Precup, Yoshua Bengio paper (arXiv) \/ GitHub (work largely done during Harry, Harm and Romain&#8217;s time at MSR) [Accepted @ICLR2024]This is our 2nd work on integrating conscious information processing behavior into Reinforcement Learning (RL) agents. Specifically, this paper seeks to address the inabilities of &#8230; <a title=\"Consciousness-Inspired Spatio-Temporal Abstractions for Better Generalization\" class=\"read-more\" href=\"http:\/\/localhost\/homepage\/combining-spatial-and-temporal-abstraction-in-planning\/\" aria-label=\"Read more about Consciousness-Inspired Spatio-Temporal Abstractions for Better Generalization\">Read more<\/a><\/p>\n","protected":false},"author":1,"featured_media":0,"parent":0,"menu_order":0,"comment_status":"closed","ping_status":"closed","template":"","meta":{"footnotes":""},"_links":{"self":[{"href":"http:\/\/localhost\/homepage\/wp-json\/wp\/v2\/pages\/494"}],"collection":[{"href":"http:\/\/localhost\/homepage\/wp-json\/wp\/v2\/pages"}],"about":[{"href":"http:\/\/localhost\/homepage\/wp-json\/wp\/v2\/types\/page"}],"author":[{"embeddable":true,"href":"http:\/\/localhost\/homepage\/wp-json\/wp\/v2\/users\/1"}],"replies":[{"embeddable":true,"href":"http:\/\/localhost\/homepage\/wp-json\/wp\/v2\/comments?post=494"}],"version-history":[{"count":17,"href":"http:\/\/localhost\/homepage\/wp-json\/wp\/v2\/pages\/494\/revisions"}],"predecessor-version":[{"id":555,"href":"http:\/\/localhost\/homepage\/wp-json\/wp\/v2\/pages\/494\/revisions\/555"}],"wp:attachment":[{"href":"http:\/\/localhost\/homepage\/wp-json\/wp\/v2\/media?parent=494"}],"curies":[{"name":"wp","href":"https:\/\/api.w.org\/{rel}","templated":true}]}}